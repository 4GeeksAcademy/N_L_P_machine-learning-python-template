{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                             https://www.hvper.com/     True\n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                        https://briefingday.com/fan     True"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Your code here\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import regex as re\n",
                "archivo = 'https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv'\n",
                "total_data  = pd.read_csv(archivo)\n",
                "total_data.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Index(['url', 'is_spam'], dtype='object')\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                             https://www.hvper.com/     True\n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                        https://briefingday.com/fan     True"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "print(total_data.columns)\n",
                "total_data.head() "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                                                 url  is_spam\n",
                        "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                        "1                             https://www.hvper.com/     True\n",
                        "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                        "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                        "4                        https://briefingday.com/fan     True\n",
                        "5  https://www.brookings.edu/interactives/reopeni...    False\n",
                        "6  https://www.reuters.com/investigates/special-r...    False\n",
                        "7  https://www.theatlantic.com/magazine/archive/2...    False\n",
                        "8  https://www.vox.com/2020/6/17/21294680/john-bo...    False\n",
                        "9  https://www.theguardian.com/travel/2020/jun/18...    False\n"
                    ]
                }
            ],
            "source": [
                "print(total_data.head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                                                 url  is_spam  is_spam_int\n",
                        "0  https://briefingday.us8.list-manage.com/unsubs...     True            1\n",
                        "1                             https://www.hvper.com/     True            1\n",
                        "2                 https://briefingday.com/m/v4n3i4f3     True            1\n",
                        "3   https://briefingday.com/n/20200618/m#commentform    False            0\n",
                        "4                        https://briefingday.com/fan     True            1\n"
                    ]
                }
            ],
            "source": [
                "total_data[\"is_spam_int\"] = total_data[\"is_spam\"].astype(int)\n",
                "print(total_data.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "transformar en 1 y 0 "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                                                 url  is_spam_int\n",
                        "0  https://briefingday.us8.list-manage.com/unsubs...            1\n",
                        "1                             https://www.hvper.com/            1\n",
                        "2                 https://briefingday.com/m/v4n3i4f3            1\n",
                        "3   https://briefingday.com/n/20200618/m#commentform            0\n",
                        "4                        https://briefingday.com/fan            1\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "total_data.drop(columns=['is_spam'], inplace=True)\n",
                "\n",
                "\n",
                "print(total_data.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "eliminar los duplicados "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Forma del DataFrame antes de eliminar duplicados: (2999, 2)\n",
                        "Forma del DataFrame después de eliminar duplicados: (2369, 2)\n",
                        "                                                 url  is_spam_int\n",
                        "0  https://briefingday.us8.list-manage.com/unsubs...            1\n",
                        "1                             https://www.hvper.com/            1\n",
                        "2                 https://briefingday.com/m/v4n3i4f3            1\n",
                        "3   https://briefingday.com/n/20200618/m#commentform            0\n",
                        "4                        https://briefingday.com/fan            1\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "print(f\"Forma del DataFrame antes de eliminar duplicados: {total_data.shape}\")\n",
                "\n",
                "total_data.drop_duplicates(inplace=True)\n",
                "\n",
                "total_data.reset_index(inplace=True, drop=True)\n",
                "print(f\"Forma del DataFrame después de eliminar duplicados: {total_data.shape}\")\n",
                "\n",
                "print(total_data.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Procesamiento del texto"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_text(text):\n",
                "    \n",
                "    text = re.sub(r'[^a-z ]', \" \", text)\n",
                "\n",
                "   \n",
                "    text = re.sub(r'\\s+[a-zA-Z]\\s+', \" \", text)\n",
                "    text = re.sub(r'\\^[a-zA-Z]\\s+', \" \", text)\n",
                "\n",
                "    \n",
                "    text = re.sub(r'\\s+', \" \", text.lower())\n",
                "\n",
                "   \n",
                "    text = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \", text)\n",
                "\n",
                "    return text.split()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam_int</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>[https, briefingday, us, list, manage, com, un...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>[https, www, hvper, com]</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>[https, briefingday, com, v, i]</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>[https, briefingday, com, m, commentform]</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>[https, briefingday, com, fan]</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam_int\n",
                            "0  [https, briefingday, us, list, manage, com, un...            1\n",
                            "1                           [https, www, hvper, com]            1\n",
                            "2                    [https, briefingday, com, v, i]            1\n",
                            "3          [https, briefingday, com, m, commentform]            0\n",
                            "4                     [https, briefingday, com, fan]            1"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "total_data[\"url\"] = total_data[\"url\"].apply(preprocess_text)\n",
                "total_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Lematizacion "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                                                 url  \\\n",
                        "0  [https, briefingday, us, list, manage, com, un...   \n",
                        "1                           [https, www, hvper, com]   \n",
                        "2                    [https, briefingday, com, v, i]   \n",
                        "3          [https, briefingday, com, m, commentform]   \n",
                        "4                     [https, briefingday, com, fan]   \n",
                        "\n",
                        "                                   url_lemmatized  \n",
                        "0  http briefingday u list manage com unsubscribe  \n",
                        "1                              http www hvper com  \n",
                        "2                        http briefingday com v i  \n",
                        "3              http briefingday com m commentform  \n",
                        "4                        http briefingday com fan  \n"
                    ]
                }
            ],
            "source": [
                "import nltk\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "from nltk.corpus import stopwords\n",
                "\n",
                "\n",
                "try:\n",
                "    stopwords.words('english')\n",
                "except LookupError:\n",
                "    nltk.download('stopwords')\n",
                "try:\n",
                "    WordNetLemmatizer().lemmatize('testing')\n",
                "except LookupError:\n",
                "    nltk.download('wordnet')\n",
                "\n",
                "\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "\n",
                "def lemmatize_tokens(tokens):\n",
                "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
                "    return \" \".join(lemmatized_tokens)\n",
                "\n",
                "total_data[\"url_lemmatized\"] = total_data[\"url\"].apply(lemmatize_tokens)\n",
                "\n",
                "\n",
                "print(total_data[['url', 'url_lemmatized']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "tokenización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Primeras 5 filas de la matriz de características X:\n",
                        "[[0. 0. 0. ... 0. 0. 0.]\n",
                        " [0. 0. 0. ... 0. 0. 0.]\n",
                        " [0. 0. 0. ... 0. 0. 0.]\n",
                        " [0. 0. 0. ... 0. 0. 0.]\n",
                        " [0. 0. 0. ... 0. 0. 0.]]\n",
                        "\n",
                        "Forma de la matriz de características X: (2369, 691)\n",
                        "Forma del vector objetivo y: (2369,)\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "\n",
                "tokens_list = total_data[\"url\"]\n",
                "tokens_list = [\" \".join(tokens) for tokens in tokens_list]\n",
                "\n",
                "vectorizer = TfidfVectorizer(max_features=5000, max_df=0.8, min_df=5)\n",
                "\n",
                "X = vectorizer.fit_transform(tokens_list).toarray()\n",
                "\n",
                "y = total_data[\"is_spam_int\"]\n",
                "\n",
                "\n",
                "print(\"Primeras 5 filas de la matriz de características X:\")\n",
                "print(X[:5])\n",
                "\n",
                "\n",
                "print(\"\\nForma de la matriz de características X:\", X.shape)\n",
                "print(\"Forma del vector objetivo y:\", y.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Modelo "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Forma de X_train: (1895, 691)\n",
                        "Forma de X_test: (474, 691)\n",
                        "Forma de y_train: (1895,)\n",
                        "Forma de y_test: (474,)\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(\"Forma de X_train:\", X_train.shape)\n",
                "print(\"Forma de X_test:\", X_test.shape)\n",
                "print(\"Forma de y_train:\", y_train.shape)\n",
                "print(\"Forma de y_test:\", y_test.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modelo SVM con kernel lineal entrenado.\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.svm import SVC\n",
                "\n",
                "model = SVC(kernel=\"linear\", random_state=42)\n",
                "\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "print(\"Modelo SVM con kernel lineal entrenado.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicciones del modelo SVM en el conjunto de prueba:\n",
                        "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
                        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
                        " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
                        " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
                        " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
                    ]
                }
            ],
            "source": [
                "# Realizar predicciones en el conjunto de prueba\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "\n",
                "print(\"Predicciones del modelo SVM en el conjunto de prueba:\")\n",
                "print(y_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Precisión del modelo SVM (kernel lineal) en el conjunto de prueba: 0.9599\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# Calcular la precisión del modelo\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "\n",
                "print(f\"Precisión del modelo SVM (kernel lineal) en el conjunto de prueba: {accuracy:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicción: No Spam\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "import nltk\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "from nltk.corpus import stopwords\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "try:\n",
                "    stopwords.words('english')\n",
                "except LookupError:\n",
                "    nltk.download('stopwords')\n",
                "try:\n",
                "    WordNetLemmatizer().lemmatize('testing')\n",
                "except LookupError:\n",
                "    nltk.download('wordnet')\n",
                "\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "\n",
                "def preprocess_text(text):\n",
                "    text = re.sub(r'[^a-z ]', \" \", text)\n",
                "    text = re.sub(r'\\s+[a-zA-Z]\\s+', \" \", text)\n",
                "    text = re.sub(r'\\^[a-zA-Z]\\s+', \" \", text)\n",
                "    text = re.sub(r'\\s+', \" \", text.lower())\n",
                "    text = re.sub(\"&lt;/?.*?&gt;\",\" <> \", text)\n",
                "    return text.split()\n",
                "\n",
                "def lemmatize_tokens(tokens):\n",
                "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
                "    return lemmatized_tokens  # Devolvemos una lista de tokens\n",
                "\n",
                "# Nuevo texto a predecir\n",
                "new_message = \"To receive the €350 payment, the referred person must apply with your referral code. They must be completely new to our database and have no previous sales or contact experience.\"\n",
                "\n",
                "# Aplicar preprocesamiento\n",
                "processed_message = preprocess_text(new_message)\n",
                "\n",
                "# Aplicar lematización a la lista de tokens\n",
                "lemmatized_message = lemmatize_tokens(processed_message)\n",
                "\n",
                "# Unir tokens en una sola cadena para vectorizar\n",
                "lemmatized_message_str = \" \".join(lemmatized_message)\n",
                "\n",
                "# Vectorizar utilizando el vectorizador entrenado (asegúrate de que 'vectorizer' esté definido y entrenado)\n",
                "try:\n",
                "    vectorized_message = vectorizer.transform([lemmatized_message_str]).toarray()\n",
                "\n",
                "    # Realizar predicción\n",
                "    prediction = model.predict(vectorized_message)\n",
                "\n",
                "    # Mostrar resultado\n",
                "    print(\"Predicción:\", \"Spam\" if prediction[0] == 1 else \"No Spam\")\n",
                "\n",
                "except NameError as e:\n",
                "    print(f\"Error: {e}. Asegúrate de que 'vectorizer' y 'model' estén definidos y entrenados en tu sesión.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Mejores hiperparámetros encontrados: {'C': 1}\n",
                        "\n",
                        "Accuracy del mejor modelo SVM (kernel lineal) en el conjunto de prueba: 0.9599\n",
                        "\n",
                        "Classification Report del mejor modelo SVM (kernel lineal):\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.96      1.00      0.98       435\n",
                        "           1       0.95      0.54      0.69        39\n",
                        "\n",
                        "    accuracy                           0.96       474\n",
                        "   macro avg       0.96      0.77      0.83       474\n",
                        "weighted avg       0.96      0.96      0.95       474\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import accuracy_score, classification_report  \n",
                "\n",
                "\n",
                "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
                "\n",
                "\n",
                "svm_model = SVC(kernel='linear', random_state=42)\n",
                "\n",
                "\n",
                "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
                "\n",
                "\n",
                "grid_search.fit(X_train, y_train)\n",
                "\n",
                "\n",
                "best_svm_model = grid_search.best_estimator_\n",
                "\n",
                "\n",
                "y_pred_best = best_svm_model.predict(X_test)\n",
                "\n",
                "\n",
                "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
                "best_report = classification_report(y_test, y_pred_best)\n",
                "\n",
                "print(\"\\nMejores hiperparámetros encontrados:\", grid_search.best_params_)\n",
                "print(f\"\\nAccuracy del mejor modelo SVM (kernel lineal) en el conjunto de prueba: {best_accuracy:.4f}\")\n",
                "print(\"\\nClassification Report del mejor modelo SVM (kernel lineal):\")\n",
                "print(best_report)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Modelo SVM optimizado guardado en: modelos/spam_url_svm_optimized.joblib\n",
                        "Vectorizador TF-IDF guardado en: modelos/tfidf_vectorizer.joblib\n"
                    ]
                }
            ],
            "source": [
                "import joblib\n",
                "import os\n",
                "\n",
                "# Definir la ruta de la carpeta donde guardar el modelo\n",
                "model_folder = 'modelos'\n",
                "os.makedirs(model_folder, exist_ok=True)\n",
                "model_path = os.path.join(model_folder, 'spam_url_svm_optimized.joblib')\n",
                "vectorizer_path = os.path.join(model_folder, 'tfidf_vectorizer.joblib')\n",
                "\n",
                "# Guardar el mejor modelo SVM optimizado\n",
                "joblib.dump(best_svm_model, model_path)\n",
                "print(f\"\\nModelo SVM optimizado guardado en: {model_path}\")\n",
                "\n",
                "\n",
                "joblib.dump(vectorizer, vectorizer_path)\n",
                "print(f\"Vectorizador TF-IDF guardado en: {vectorizer_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
